#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Test ETL Pipeline ƒë∆°n gi·∫£n - ch·ªâ 1 file duy nh·∫•t
Test c√°c ch·ª©c nƒÉng c∆° b·∫£n c·ªßa ETL t·ª´ Staging sang DWH
"""

import os
import sys
import json
import pytest
import pandas as pd
from datetime import datetime, timedelta
import tempfile

# Setup path
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
sys.path.insert(0, PROJECT_ROOT)

# Import functions to test
from src.processing.data_prepare import (
    parse_job_location, calculate_load_month, 
    prepare_dim_job, prepare_dim_company, prepare_dim_location,
    generate_daily_fact_records
)

class TestETLPipelineSimple:
    """Test class ƒë∆°n gi·∫£n cho ETL Pipeline"""
    
    @pytest.fixture
    def sample_data(self):
        """T·∫°o d·ªØ li·ªáu test ƒë∆°n gi·∫£n"""
        return pd.DataFrame({
            'job_id': ['JOB001', 'JOB002'],
            'title_clean': ['Python Developer', 'Java Developer'],
            'job_url': ['https://jobs.com/1', 'https://jobs.com/2'],
            'skills': ['["Python", "Django"]', '["Java", "Spring"]'],
            'last_update': ['2025-05-28', '2025-05-29'],
            'logo_url': ['https://logo1.png', 'https://logo2.png'],
            'company_name': ['Tech Corp', 'Dev Company'],
            'company_name_standardized': ['Tech Corp Ltd', 'Dev Company Inc'],
            'company_url': ['https://techcorp.com', 'https://devcompany.com'],
            'verified_employer': [True, False],
            'location_pairs': ['["H√† N·ªôi: C·∫ßu Gi·∫•y"]', '["TP.HCM"]']
        })
    
    def test_location_parsing(self):
        """Test parsing location - ch·ª©c nƒÉng c∆° b·∫£n nh·∫•t"""
        print("\n=== Test Location Parsing ===")
        
        # Test case ƒë∆°n gi·∫£n
        location = '["H√† N·ªôi: C·∫ßu Gi·∫•y, ƒê·ªëng ƒêa"]'
        result = parse_job_location(location)
        
        print(f"Input: {location}")
        print(f"Output: {result}")
        
        # Ki·ªÉm tra k·∫øt qu·∫£
        assert len(result) == 2  # Should have 2 districts
        assert (None, 'H√† N·ªôi', 'C·∫ßu Gi·∫•y') in result
        assert (None, 'H√† N·ªôi', 'ƒê·ªëng ƒêa') in result
        
        # Test case ƒë∆°n gi·∫£n h∆°n
        simple_location = 'ƒê√† N·∫µng'
        result = parse_job_location(simple_location)
        assert result == [(None, 'ƒê√† N·∫µng', None)]
        
        print("‚úÖ Location parsing test passed")
    
    def test_calculate_load_month(self):
        """Test t√≠nh to√°n th√°ng ƒë·ªÉ partition"""
        print("\n=== Test Calculate Load Month ===")
        
        # Test v·ªõi datetime
        dt = datetime(2025, 5, 29)
        result = calculate_load_month(dt)
        assert result == "2025-05"
        
        # Test v·ªõi string date
        result = calculate_load_month("2025-03-15")
        assert result == "2025-03"
        
        # Test v·ªõi None (should return current month)
        result = calculate_load_month(None)
        current_month = datetime.now().strftime('%Y-%m')
        assert result == current_month
        
        print(f"‚úÖ Load month calculation test passed")
    
    def test_generate_daily_fact_records(self):
        """Test t·∫°o daily fact records"""
        print("\n=== Test Generate Daily Fact Records ===")
        
        # Test v·ªõi kho·∫£ng ng√†y c·ª• th·ªÉ
        posted = datetime(2025, 5, 25)
        due = datetime(2025, 5, 27)
        dates = generate_daily_fact_records(posted, due)
        
        expected_dates = [
            datetime(2025, 5, 25).date(),
            datetime(2025, 5, 26).date(),
            datetime(2025, 5, 27).date()
        ]
        
        assert dates == expected_dates
        print(f"Generated {len(dates)} dates from {posted.date()} to {due.date()}")
        
        print("‚úÖ Daily fact records test passed")
    
    def test_prepare_dim_job(self, sample_data):
        """Test chu·∫©n b·ªã d·ªØ li·ªáu DimJob"""
        print("\n=== Test Prepare DimJob ===")
        
        result = prepare_dim_job(sample_data)
        
        # Ki·ªÉm tra s·ªë l∆∞·ª£ng records
        assert len(result) == len(sample_data)
        
        # Ki·ªÉm tra c√≥ c√°c columns c·∫ßn thi·∫øt
        required_columns = ['job_id', 'title_clean', 'skills', 'effective_date', 'is_current']
        for col in required_columns:
            assert col in result.columns
        
        # Ki·ªÉm tra skills l√† JSON string
        for _, row in result.iterrows():
            skills = row['skills']
            assert isinstance(skills, str)
            # Should be valid JSON
            json.loads(skills)
        
        # Ki·ªÉm tra SCD2 fields
        assert all(result['is_current'] == True)
        
        print(f"‚úÖ DimJob preparation test passed - {len(result)} records")
    
    def test_prepare_dim_company(self, sample_data):
        """Test chu·∫©n b·ªã d·ªØ li·ªáu DimCompany"""
        print("\n=== Test Prepare DimCompany ===")
        
        result = prepare_dim_company(sample_data)
        
        # Ki·ªÉm tra deduplication
        unique_companies = sample_data['company_name_standardized'].nunique()
        assert len(result) == unique_companies
        
        # Ki·ªÉm tra c√≥ c√°c columns c·∫ßn thi·∫øt
        required_columns = ['company_name_standardized', 'company_url', 'verified_employer', 'is_current']
        for col in required_columns:
            assert col in result.columns
        
        print(f"‚úÖ DimCompany preparation test passed - {len(result)} records")
    
    def test_prepare_dim_location(self, sample_data):
        """Test chu·∫©n b·ªã d·ªØ li·ªáu DimLocation"""
        print("\n=== Test Prepare DimLocation ===")
        
        result = prepare_dim_location(sample_data)
        
        # Ki·ªÉm tra c√≥ √≠t nh·∫•t m·ªôt s·ªë records
        assert len(result) > 0
        
        # Ki·ªÉm tra c√≥ c√°c columns c·∫ßn thi·∫øt
        required_columns = ['province', 'city', 'district', 'is_current']
        for col in required_columns:
            assert col in result.columns
        
        # Ki·ªÉm tra t·∫•t c·∫£ c√≥ city
        assert all(pd.notna(result['city']))
        
        print(f"‚úÖ DimLocation preparation test passed - {len(result)} records")
        for _, row in result.iterrows():
            print(f"  Location: {row['province']} | {row['city']} | {row['district']}")
    
    def test_data_quality_checks(self):
        """Test data quality validation"""
        print("\n=== Test Data Quality ===")
        
        # Test v·ªõi d·ªØ li·ªáu c√≥ v·∫•n ƒë·ªÅ - ph·∫£i c√≥ ƒë·ªß columns ƒë·ªÉ test
        bad_data = pd.DataFrame({
            'job_id': ['JOB001', '', None],
            'title_clean': ['Good Title', '', None],
            'job_url': ['https://job1.com', '', None],
            'skills': ['["Python"]', '', None],
            'last_update': ['2025-05-28', '', None],
            'logo_url': ['https://logo1.png', '', None],
            'company_name_standardized': ['Good Company', '', None],
            'location_pairs': ['["H√† N·ªôi"]', '', None]
        })
        
        # Test DimJob v·ªõi bad data
        result = prepare_dim_job(bad_data)
        
        # Ki·ªÉm tra null title ƒë∆∞·ª£c handle
        titles = result['title_clean'].tolist()
        assert 'Unknown Title' in titles  # Should replace null/empty with this
        assert 'Good Title' in titles     # Should keep good data
        
        print("‚úÖ Data quality checks passed")
    
    def test_integration_flow(self, sample_data):
        """Test integration c·ªßa to√†n b·ªô flow"""
        print("\n=== Test Integration Flow ===")
        
        # Step 1: Prepare all dimensions
        dim_job = prepare_dim_job(sample_data)
        dim_company = prepare_dim_company(sample_data)
        dim_location = prepare_dim_location(sample_data)
        
        print(f"Prepared dimensions:")
        print(f"  - DimJob: {len(dim_job)} records")
        print(f"  - DimCompany: {len(dim_company)} records") 
        print(f"  - DimLocation: {len(dim_location)} records")
        
        # Step 2: Check load month calculation
        load_months = []
        for _, row in sample_data.iterrows():
            load_month = calculate_load_month(row['last_update'])
            load_months.append(load_month)
        
        print(f"Load months: {set(load_months)}")
        
        # Step 3: Generate some fact dates
        posted = datetime(2025, 5, 28)
        fact_dates = generate_daily_fact_records(posted, None)
        
        print(f"Generated fact dates: {len(fact_dates)} days")
        
        # Basic validations
        assert len(dim_job) > 0
        assert len(dim_company) > 0
        assert len(dim_location) > 0
        assert len(load_months) > 0
        assert len(fact_dates) > 0
        
        print("‚úÖ Integration flow test passed")
    
    def run_all_tests(self):
        """Ch·∫°y t·∫•t c·∫£ tests"""
        print("üöÄ Starting Simple ETL Tests...")
        
        # Create sample data
        sample_data = pd.DataFrame({
            'job_id': ['JOB001', 'JOB002'],
            'title_clean': ['Python Developer', 'Java Developer'],
            'job_url': ['https://jobs.com/1', 'https://jobs.com/2'],
            'skills': ['["Python", "Django"]', '["Java", "Spring"]'],
            'last_update': ['2025-05-28', '2025-05-29'],
            'logo_url': ['https://logo1.png', 'https://logo2.png'],
            'company_name': ['Tech Corp', 'Dev Company'],
            'company_name_standardized': ['Tech Corp Ltd', 'Dev Company Inc'],
            'company_url': ['https://techcorp.com', 'https://devcompany.com'],
            'verified_employer': [True, False],
            'location_pairs': ['["H√† N·ªôi: C·∫ßu Gi·∫•y"]', '["TP.HCM"]']
        })
        
        try:
            self.test_location_parsing()
            self.test_calculate_load_month()
            self.test_generate_daily_fact_records()
            self.test_prepare_dim_job(sample_data)
            self.test_prepare_dim_company(sample_data)
            self.test_prepare_dim_location(sample_data)
            self.test_data_quality_checks()
            self.test_integration_flow(sample_data)
            
            print("\nüéâ All tests passed successfully!")
            
        except Exception as e:
            print(f"\n‚ùå Test failed: {e}")
            raise


if __name__ == "__main__":
    # Ch·∫°y tests
    tester = TestETLPipelineSimple()
    tester.run_all_tests()
    
    print("\n" + "="*50)
    print("ETL PIPELINE TEST COMPLETE")
    print("="*50)
    print("‚úÖ Location parsing")
    print("‚úÖ Date/month calculations") 
    print("‚úÖ Dimension preparations")
    print("‚úÖ Data quality checks")
    print("‚úÖ Integration flow")
    print("\nETL pipeline is ready! üöÄ")
